{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef04b29-83ea-4d81-ba8a-6f69cd1a734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: ['2020.csv', '2021.csv', '2023.csv', '2022.csv', '2024.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country name</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness score</th>\n",
       "      <th>Upperwhisker</th>\n",
       "      <th>Lowerwhisker</th>\n",
       "      <th>Economy (GDP per Capita)\\t</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>1</td>\n",
       "      <td>7.81</td>\n",
       "      <td>7.87</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.49</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.62</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country name  Happiness Rank  Happiness score  Upperwhisker  Lowerwhisker  \\\n",
       "0      Finland               1             7.81          7.87          7.75   \n",
       "1      Denmark               2             7.65          7.71          7.58   \n",
       "2  Switzerland               3             7.56          7.63          7.49   \n",
       "3      Iceland               4             7.50          7.62          7.39   \n",
       "4       Norway               5             7.49          7.56          7.42   \n",
       "\n",
       "   Economy (GDP per Capita)\\t  Social support  Healthy life expectancy  \\\n",
       "0                        1.29            1.50                     0.96   \n",
       "1                        1.33            1.50                     0.98   \n",
       "2                        1.39            1.47                     1.04   \n",
       "3                        1.33            1.55                     1.00   \n",
       "4                        1.42            1.50                     1.01   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  Year  \n",
       "0                          0.66        0.16                       0.48  2020  \n",
       "1                          0.67        0.24                       0.50  2020  \n",
       "2                          0.63        0.27                       0.41  2020  \n",
       "3                          0.66        0.36                       0.14  2020  \n",
       "4                          0.67        0.29                       0.43  2020  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List all CSV files in the current directory\n",
    "csv_files = [file for file in os.listdir() if file.endswith('.csv')]\n",
    "\n",
    "# Optional: print to verify\n",
    "print(\"Files found:\", csv_files)\n",
    "\n",
    "# Load and combine\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Year'] = file[-8:-4]  # Adjust this based on your file naming, or use a cleaner method if needed\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Preview it\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44a891c-4c78-4b76-9a77-894dcfbfcf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Files Found (5): ['2020.csv', '2021.csv', '2023.csv', '2022.csv', '2024.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_files = [file for file in os.listdir() if file.endswith('.csv')]\n",
    "print(f\"CSV Files Found ({len(csv_files)}):\", csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88662a07-df56-4ba7-8f92-9a9973f88fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Shape: (728, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country name</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness score</th>\n",
       "      <th>Upperwhisker</th>\n",
       "      <th>Lowerwhisker</th>\n",
       "      <th>Economy (GDP per Capita)\\t</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>1</td>\n",
       "      <td>7.81</td>\n",
       "      <td>7.87</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.49</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.62</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>6</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>7</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>8</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Austria</td>\n",
       "      <td>9</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.36</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>10</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country name  Happiness Rank  Happiness score  Upperwhisker  Lowerwhisker  \\\n",
       "0      Finland               1             7.81          7.87          7.75   \n",
       "1      Denmark               2             7.65          7.71          7.58   \n",
       "2  Switzerland               3             7.56          7.63          7.49   \n",
       "3      Iceland               4             7.50          7.62          7.39   \n",
       "4       Norway               5             7.49          7.56          7.42   \n",
       "5  Netherlands               6             7.45          7.50          7.39   \n",
       "6       Sweden               7             7.35          7.42          7.28   \n",
       "7  New Zealand               8             7.30          7.38          7.22   \n",
       "8      Austria               9             7.29          7.36          7.23   \n",
       "9   Luxembourg              10             7.24          7.30          7.18   \n",
       "\n",
       "   Economy (GDP per Capita)\\t  Social support  Healthy life expectancy  \\\n",
       "0                        1.29            1.50                     0.96   \n",
       "1                        1.33            1.50                     0.98   \n",
       "2                        1.39            1.47                     1.04   \n",
       "3                        1.33            1.55                     1.00   \n",
       "4                        1.42            1.50                     1.01   \n",
       "5                        1.34            1.46                     0.98   \n",
       "6                        1.32            1.43                     0.99   \n",
       "7                        1.24            1.49                     1.01   \n",
       "8                        1.32            1.44                     1.00   \n",
       "9                        1.54            1.39                     0.99   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  Year  \n",
       "0                          0.66        0.16                       0.48  2020  \n",
       "1                          0.67        0.24                       0.50  2020  \n",
       "2                          0.63        0.27                       0.41  2020  \n",
       "3                          0.66        0.36                       0.14  2020  \n",
       "4                          0.67        0.29                       0.43  2020  \n",
       "5                          0.61        0.34                       0.37  2020  \n",
       "6                          0.65        0.27                       0.44  2020  \n",
       "7                          0.65        0.33                       0.46  2020  \n",
       "8                          0.60        0.26                       0.28  2020  \n",
       "9                          0.61        0.20                       0.37  2020  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Year'] = file.split('.')[0]  # Adjust if needed based on filename format\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Combined Shape:\", combined_df.shape)\n",
    "combined_df.head(10)  # See the first 10 rows for variety\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213f8b14-dea5-4bf8-8bff-554524690e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Country name', 'Happiness Rank', 'Happiness score', 'Upperwhisker',\n",
      "       'Lowerwhisker', 'Economy (GDP per Capita)\\t', 'Social support',\n",
      "       'Healthy life expectancy', 'Freedom to make life choices', 'Generosity',\n",
      "       'Perceptions of corruption', 'Year'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values per column:\n",
      "Country name                    0\n",
      "Happiness Rank                  0\n",
      "Happiness score                 0\n",
      "Upperwhisker                    0\n",
      "Lowerwhisker                    0\n",
      "Economy (GDP per Capita)\\t      3\n",
      "Social support                  3\n",
      "Healthy life expectancy         4\n",
      "Freedom to make life choices    3\n",
      "Generosity                      3\n",
      "Perceptions of corruption       3\n",
      "Year                            0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "Country name                     object\n",
      "Happiness Rank                    int64\n",
      "Happiness score                 float64\n",
      "Upperwhisker                    float64\n",
      "Lowerwhisker                    float64\n",
      "Economy (GDP per Capita)\\t      float64\n",
      "Social support                  float64\n",
      "Healthy life expectancy         float64\n",
      "Freedom to make life choices    float64\n",
      "Generosity                      float64\n",
      "Perceptions of corruption       float64\n",
      "Year                             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check column names, missing values, and data types\n",
    "print(\"Columns:\", combined_df.columns)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(combined_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fe6bf4-54be-4146-b400-a3bd6ad99347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace and tab characters from column names\n",
    "combined_df.columns = combined_df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163a63f9-4454-46d8-bf97-5e5b00056146",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Year'] = combined_df['Year'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4a6777-2baa-4145-9dac-3854e839f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67380bb4-6ecb-414f-82c0-b11074d154a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned columns: ['Country name', 'Happiness Rank', 'Happiness score', 'Upperwhisker', 'Lowerwhisker', 'Economy (GDP per Capita)', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Year']\n",
      "\n",
      "🧼 Remaining missing values:\n",
      " Country name                    0\n",
      "Happiness Rank                  0\n",
      "Happiness score                 0\n",
      "Upperwhisker                    0\n",
      "Lowerwhisker                    0\n",
      "Economy (GDP per Capita)        0\n",
      "Social support                  0\n",
      "Healthy life expectancy         0\n",
      "Freedom to make life choices    0\n",
      "Generosity                      0\n",
      "Perceptions of corruption       0\n",
      "Year                            0\n",
      "dtype: int64\n",
      "\n",
      "📐 Data types:\n",
      " Country name                     object\n",
      "Happiness Rank                    int64\n",
      "Happiness score                 float64\n",
      "Upperwhisker                    float64\n",
      "Lowerwhisker                    float64\n",
      "Economy (GDP per Capita)        float64\n",
      "Social support                  float64\n",
      "Healthy life expectancy         float64\n",
      "Freedom to make life choices    float64\n",
      "Generosity                      float64\n",
      "Perceptions of corruption       float64\n",
      "Year                              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Cleaned columns:\", combined_df.columns.tolist())\n",
    "print(\"\\n🧼 Remaining missing values:\\n\", combined_df.isnull().sum())\n",
    "print(\"\\n📐 Data types:\\n\", combined_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29885db-0adc-413a-9cb7-cfdb687ece24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reduced DataFrame shape: (143, 8)\n",
      "🧠 Remaining columns: ['Happiness score', 'Economy (GDP per Capita)\\t', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Year']\n"
     ]
    }
   ],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = [\n",
    "    'Country name', 'Happiness Rank', 'Upperwhisker', 'Lowerwhisker'\n",
    "]\n",
    "\n",
    "# Create reduced DataFrame\n",
    "reduced_df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"✅ Reduced DataFrame shape:\", reduced_df.shape)\n",
    "print(\"🧠 Remaining columns:\", reduced_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babfc3bb-96b1-4856-9e84-ffd8c2511aad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m y = reduced_df[\u001b[33m'\u001b[39m\u001b[33mHappiness score\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m model = LinearRegression()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m importance = pd.Series(model.coef_, index=X.columns)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLinear Regression Coefficients:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:601\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    597\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    599\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2959\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1365\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1368\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1389\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/happiness_clean/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = reduced_df.drop(columns=['Happiness score'])\n",
    "y = reduced_df['Happiness score']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = pd.Series(model.coef_, index=X.columns)\n",
    "print(\"Linear Regression Coefficients:\")\n",
    "print(importance.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b445e6b9-f521-4862-b7ab-a27b3c2a5b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Economy (GDP per Capita)\\t      3\n",
       "Social support                  3\n",
       "Healthy life expectancy         3\n",
       "Freedom to make life choices    3\n",
       "Generosity                      3\n",
       "Perceptions of corruption       3\n",
       "Year                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03bc9059-ec21-437c-b877-ac5b83cb5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_clean = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "y_clean = y.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535ac377-aa09-4204-b819-074614ffdffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Coefficients (Feature Importance):\n",
      "Freedom to make life choices    1.896792\n",
      "Social support                  1.438366\n",
      "Healthy life expectancy         1.382510\n",
      "Perceptions of corruption       1.007223\n",
      "Generosity                      0.462057\n",
      "Economy (GDP per Capita)\\t      0.441487\n",
      "Year                            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_clean, y_clean)\n",
    "\n",
    "importance = pd.Series(model.coef_, index=X.columns)\n",
    "print(\"Linear Regression Coefficients (Feature Importance):\")\n",
    "print(importance.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55121fe-4e2d-4bd4-bd0a-7f8fe81d947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalization complete. Here's the first few rows:\n",
      "   Economy (GDP per Capita)\\t  Social support  Healthy life expectancy  \\\n",
      "0                    0.861280        0.972171                 0.810968   \n",
      "1                    0.891172        0.940012                 0.815636   \n",
      "2                    0.878561        1.000000                 0.837806   \n",
      "3                    0.877160        0.928262                 0.844807   \n",
      "4                    0.842130        0.935683                 0.863477   \n",
      "\n",
      "   Freedom to make life choices  Generosity  Perceptions of corruption  Year  \\\n",
      "0                      0.995365    0.354115                   0.949565   0.0   \n",
      "1                      0.953650    0.508728                   0.953043   0.0   \n",
      "2                      0.949015    0.643392                   0.316522   0.0   \n",
      "3                      0.971031    0.551122                   0.911304   0.0   \n",
      "4                      0.742758    0.381546                   0.335652   0.0   \n",
      "\n",
      "   Happiness score  \n",
      "0            7.741  \n",
      "1            7.583  \n",
      "2            7.525  \n",
      "3            7.344  \n",
      "4            7.341  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a copy of the reduced data to normalize\n",
    "features_to_normalize = reduced_df.drop(columns=['Happiness score'])\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling\n",
    "normalized_array = scaler.fit_transform(features_to_normalize)\n",
    "normalized_df = pd.DataFrame(normalized_array, columns=features_to_normalize.columns)\n",
    "\n",
    "# Add back the target column\n",
    "normalized_df['Happiness score'] = reduced_df['Happiness score'].values\n",
    "\n",
    "print(\"✅ Normalization complete. Here's the first few rows:\")\n",
    "print(normalized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68bd7987-58df-4cb2-abb9-1846903a9078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Discretization complete. Sample:\n",
      "   Happiness score Happiness Category\n",
      "0            7.741               High\n",
      "1            7.583               High\n",
      "2            7.525               High\n",
      "3            7.344               High\n",
      "4            7.341               High\n"
     ]
    }
   ],
   "source": [
    "# Discretize Happiness score into 3 bins\n",
    "bins = 3\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "normalized_df['Happiness Category'] = pd.cut(\n",
    "    normalized_df['Happiness score'],\n",
    "    bins=bins,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 Discretization complete. Sample:\")\n",
    "print(normalized_df[['Happiness score', 'Happiness Category']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9835a90a-b6cf-4fb8-af08-29e61366ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = reduced_df.copy()\n",
    "final_df['Happiness Category'] = pd.cut(\n",
    "    final_df['Happiness score'],\n",
    "    bins=3,\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Save it to a CSV file\n",
    "final_df.to_csv('happiness_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262a2cc-2066-49fe-b137-52e54f34a3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
